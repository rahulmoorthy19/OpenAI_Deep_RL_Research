{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Q Network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuBAjdID8EvR",
        "colab_type": "code",
        "outputId": "ae20ab5e-0803-4082-a523-cf0e0187ee99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "!pip install gym "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.17.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.12.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.18.3)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3PWIxzv8M_Q",
        "colab_type": "code",
        "outputId": "6f63a483-f123-483b-f5a4-b8a2bef0818b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!pip install atari-py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: atari-py in /usr/local/lib/python3.6/dist-packages (0.2.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from atari-py) (1.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from atari-py) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM-WXJHT8Vgk",
        "colab_type": "code",
        "outputId": "a947446a-8f22-45df-fb58-3d58af20b5bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "!pip install gym[atari]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.6/dist-packages (0.17.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.12.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.3.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (0.2.6)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (7.0.0)\n",
            "Requirement already satisfied: opencv-python; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (4.1.2.30)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari]) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1SbGSl08dpV",
        "colab_type": "text"
      },
      "source": [
        "# Implementation details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aPsv_Uw8gnW",
        "colab_type": "text"
      },
      "source": [
        "There are 5 modules of Deep Q learning-\n",
        "1. CNN for interacting with the environment\n",
        "2. Experience replay so that gradient descent converges rather than diverges. It basically provides a sense of direction to where to move for reducing the loss\n",
        "3. A module to integrate both of the above modules and building a linking peice to complete the algorithm\n",
        "4. testing with the OpenAI gym environment\n",
        "5. Preprocessing of image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhN9HfBa8m8W",
        "colab_type": "text"
      },
      "source": [
        "# import statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-c4ry1e8hw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "import tensorflow as tf\n",
        "from skimage.color import rgb2gray\n",
        "from collections import deque\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s60GirGLC2vZ",
        "colab_type": "text"
      },
      "source": [
        "# Initializing Gym environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7MM5qEoK_elV",
        "colab": {}
      },
      "source": [
        "env = gym.make(\"Breakout-v4\")\n",
        "env = env.unwrapped\n",
        "env.seed(1)\n",
        "state = env.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mku2QVDzSotY",
        "colab_type": "text"
      },
      "source": [
        "# Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74I-fefRSpob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "action_number=env.action_space.n\n",
        "learning_rate=0.01\n",
        "batch_size=64\n",
        "stack_size = 4\n",
        "pretrain_length = batch_size   \n",
        "memory_size = 1000000         \n",
        "total_episodes = 50\n",
        "threshold_epsilon=0.5\n",
        "gamma=0.9\n",
        "state_size = [84, 84, 4]  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsLNN1h3ASUL",
        "colab_type": "text"
      },
      "source": [
        "# Pre processing of image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HzU9oweAEaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def frame_preprocessing(image_frame):\n",
        "  gray = rgb2gray(image_frame)\n",
        "  cropped_frame = gray[8:-12,4:-12]\n",
        "  normalized_frame = cropped_frame/255.0\n",
        "  preprocessed_frame = resize(normalized_frame, [84,84])\n",
        "  return preprocessed_frame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl3EuAquEERE",
        "colab_type": "text"
      },
      "source": [
        "# Experience replay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH5syw0iRZPn",
        "colab_type": "text"
      },
      "source": [
        "## Stacking frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1958wlWRYP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stacked_frames  =  deque([np.zeros((84,84), dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
        "def stack_frames(stacked_frames, state, is_new_episode):\n",
        "    frame=frame_preprocessing(state)\n",
        "    if is_new_episode:\n",
        "        stacked_frames = deque([np.zeros((84,84), dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
        "        stacked_frames.append(frame)\n",
        "        stacked_frames.append(frame)\n",
        "        stacked_frames.append(frame)\n",
        "        stacked_frames.append(frame)\n",
        "        stacked_state = np.stack(stacked_frames, axis=2)\n",
        "    else:\n",
        "        stacked_frames.append(frame)\n",
        "        stacked_state = np.stack(stacked_frames, axis=2) \n",
        "    return stacked_state, stacked_frames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSvGn-U1DHrL",
        "colab_type": "text"
      },
      "source": [
        "## Memory class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paUaFalaC9iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory():\n",
        "    def __init__(self, max_size):\n",
        "        self.buffer = deque(maxlen = max_size)\n",
        "    \n",
        "    def add(self, experience):\n",
        "        self.buffer.append(experience)\n",
        "    \n",
        "    def sample(self, batch_size):\n",
        "        buffer_size = len(self.buffer)\n",
        "        index = np.random.choice(np.arange(buffer_size),\n",
        "                                size = batch_size,\n",
        "                                replace = False)\n",
        "        \n",
        "        return [self.buffer[i] for i in index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lx1hqJEnRt0m",
        "colab_type": "text"
      },
      "source": [
        "## Dealing with empty memory problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbWWj0GdEhHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "memory = Memory(max_size = memory_size)\n",
        "for i in range(pretrain_length):\n",
        "    if i == 0:\n",
        "        state = env.reset()\n",
        "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
        "    #possible_actions = np.array(np.identity(env.action_space.n,dtype=int).tolist())\n",
        "    action = random.randint(1,env.action_space.n)-1\n",
        "    #action = possible_actions[choice]\n",
        "    next_state, reward, done, _ = env.step(action)\n",
        "    #env.render()\n",
        "    next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
        "    if done:\n",
        "        next_state = np.zeros(state.shape)\n",
        "        possible_actions = np.array(np.identity(env.action_space.n,dtype=int).tolist())\n",
        "        action = possible_actions[action]\n",
        "        print(action.shape)\n",
        "        memory.add((state, action, reward, next_state, done))\n",
        "        state = env.reset()\n",
        "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
        "    else:\n",
        "        possible_actions = np.array(np.identity(env.action_space.n,dtype=int).tolist())\n",
        "        action = possible_actions[action]\n",
        "        memory.add((state, action, reward, next_state, done))\n",
        "        state = next_state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ThREIxSFHcG",
        "colab_type": "text"
      },
      "source": [
        "# Q Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5by7mO9GNIE",
        "colab_type": "text"
      },
      "source": [
        "The Q network architecture-\n",
        "1. 16 filters with 8 X 8 kernel and 4 strides with relu activation\n",
        "2. 32 filters with 4 X 4 kernel and 2 strides with relu activation\n",
        "3. 256 fully connected layer\n",
        "4. linear layer with number of actions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQGq6ksIE5KD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "d4c431ca-9344-4d9a-9223-15451d0bb66e"
      },
      "source": [
        "tf.compat.v1.disable_eager_execution()\n",
        "input_state=tf.compat.v1.placeholder(tf.float32, shape=[None, *state_size],name=\"input_state\")\n",
        "y_j=tf.compat.v1.placeholder(tf.float32, shape=[None],name=\"y_j\")\n",
        "action_space=tf.compat.v1.placeholder(tf.float32, shape=[None, action_number],name=\"action_space\")\n",
        "cnn_layer_1=tf.keras.layers.Conv2D(filters=16,kernel_size=(8,8),strides=(4,4),activation=\"relu\")(input_state)\n",
        "cnn_layer_2=tf.keras.layers.Conv2D(filters=32,kernel_size=(4,4),strides=(2,2),activation=\"relu\")(cnn_layer_1)\n",
        "flatten_layer=tf.keras.layers.Flatten()(cnn_layer_2)\n",
        "fully_connected_layer_1=tf.keras.layers.Dense(256,activation='relu',name=\"fully_connected_layer_1\")(flatten_layer)\n",
        "output_layer=tf.keras.layers.Dense(action_number,name=\"output_layer\")(fully_connected_layer_1)\n",
        "action_output=tf.keras.layers.Softmax(name=\"action_output\")(output_layer)\n",
        "Q_value=tf.math.reduce_sum(tf.math.multiply(output_layer, action_space))\n",
        "loss=tf.math.reduce_mean(tf.math.square(y_j-Q_value))\n",
        "training=tf.compat.v1.train.AdamOptimizer(learning_rate).minimize(loss)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko5UiAbHVG04",
        "colab_type": "text"
      },
      "source": [
        "# Training Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ny4l6-LMGCc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "83eacbb8-0d39-4192-e376-f523ef315dd4"
      },
      "source": [
        "saver = tf.compat.v1.train.Saver()\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    sess.run(tf.compat.v1.global_variables_initializer())\n",
        "    for i in range(total_episodes):\n",
        "      episode_rewards_sum = 0\n",
        "      state = env.reset()\n",
        "      #env.render()\n",
        "      state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
        "      while True:\n",
        "        epsilon=random.random()\n",
        "        if epsilon<threshold_epsilon:\n",
        "          action = random.randint(1,env.action_space.n)-1\n",
        "          next_state, reward, done, _ = env.step(action)\n",
        "        else:\n",
        "          action_probability=sess.run(action_output,feed_dict={input_state:state.reshape((1, *state.shape))})\n",
        "          action = np.random.choice(range(action_probability.shape[1]), p=action_probability.ravel())\n",
        "          next_state, reward, done, _ = env.step(action)\n",
        "        if done:\n",
        "          next_state = np.zeros(state.shape)\n",
        "          possible_actions = np.array(np.identity(env.action_space.n,dtype=int).tolist())\n",
        "          action = possible_actions[action]\n",
        "          memory.add((state, action, reward, next_state, done))\n",
        "          break\n",
        "        else:\n",
        "          next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
        "          possible_actions = np.array(np.identity(env.action_space.n,dtype=int).tolist())\n",
        "          action = possible_actions[action]\n",
        "          memory.add((state, action, reward, next_state, done))\n",
        "          state=next_state\n",
        "        batch = memory.sample(batch_size)\n",
        "        states_mb = np.array([each[0] for each in batch], ndmin=3)\n",
        "        actions_mb = np.array([each[1] for each in batch])\n",
        "        rewards_mb = np.array([each[2] for each in batch]) \n",
        "        next_states_mb = np.array([each[3] for each in batch], ndmin=3)\n",
        "        dones_mb = np.array([each[4] for each in batch])\n",
        "        target_Qs_batch = []\n",
        "        Qs_next_state = sess.run(output_layer, feed_dict = {input_state: next_states_mb})\n",
        "        for j in range(len(batch)):\n",
        "          terminal = dones_mb[i]\n",
        "          if terminal:\n",
        "            target_Qs_batch.append(rewards_mb[i])\n",
        "          else:\n",
        "            target_Qs_batch.append(rewards_mb[i]+(gamma*np.max(Qs_next_state[i])))\n",
        "        targets_mb = np.array([each for each in target_Qs_batch])\n",
        "        loss_value, _ = sess.run([loss, training],\n",
        "                           feed_dict={input_state: states_mb,\n",
        "                                      y_j: targets_mb, \n",
        "                                      action_space: actions_mb})\n",
        "      if i % 5 == 0:\n",
        "        save_path = saver.save(sess, \"./models/model.ckpt\")\n",
        "        print(\"Model Saved\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e163df3f5222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mdones_mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtarget_Qs_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mQs_next_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnext_states_mb\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m           \u001b[0mterminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdones_mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1181\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOnw6YeojM1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}